{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How I get the 20 news groups dataset\n",
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import Ipynb_importer\n",
    "from scipy.sparse import save_npz\n",
    "\n",
    "data = fetch_20newsgroups_vectorized(subset = 'all')\n",
    "\n",
    "\n",
    "target = data.target\n",
    "target_names = data.target_names\n",
    "data = data.data\n",
    "\n",
    "save_npz('20news', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import Ipynb_importer\n",
    "from deep_nmf import Deep_NMF, Energy_Loss_Func\n",
    "from writer import Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The matrix is tooo large if transformed into a torch tensor, so I have to do that in a stochastic way.\n",
    "# Here I define a dataloader that will take the subset of the sparse numpy matrix and then only transform this subset into\n",
    "# a torch Tensor, which will save memories\n",
    "\n",
    "class sparsedata(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, label,transform = None):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.len = data.shape[0]\n",
    "        assert(self.len == len(label))\n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.data[index,:]\n",
    "        if self.transform is not None:\n",
    "            inputs = self.transform(inputs)\n",
    "        target = self.label[index]\n",
    "        inputs = torch.Tensor(inputs.todense()).double()\n",
    "        if type(index) == int:\n",
    "            target = torch.Tensor([target])\n",
    "        else:\n",
    "            target = torch.Tensor(target)\n",
    "        return inputs, target\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the dataset and the dataloader\n",
    "dataset = sparsedata(data*1000, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the network structure\n",
    "m = data.shape[1]\n",
    "k1 = 200\n",
    "k2 = 20\n",
    "net = Deep_NMF([m,k1, k2])\n",
    "loss_func = Energy_Loss_Func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.6802, dtype=torch.float64)\n",
      "time for one step: 81.9965980052948\n",
      "tensor(7.6799, dtype=torch.float64)\n",
      "time for one step: 72.37643885612488\n",
      "tensor(7.6778, dtype=torch.float64)\n",
      "time for one step: 50.960200548172\n",
      "tensor(7.6682, dtype=torch.float64)\n",
      "time for one step: 18.967193603515625\n",
      "tensor(7.6366, dtype=torch.float64)\n",
      "time for one step: 18.136932373046875\n",
      "tensor(7.5207, dtype=torch.float64)\n",
      "time for one step: 17.434265851974487\n",
      "tensor(7.1609, dtype=torch.float64)\n",
      "time for one step: 17.182661294937134\n",
      "tensor(6.3933, dtype=torch.float64)\n",
      "time for one step: 17.37985324859619\n",
      "tensor(5.6757, dtype=torch.float64)\n",
      "time for one step: 17.57507872581482\n",
      "tensor(4.7706, dtype=torch.float64)\n",
      "time for one step: 17.288352489471436\n",
      "tensor(5.1873, dtype=torch.float64)\n",
      "time for one step: 40.88153433799744\n",
      "tensor(4.6627, dtype=torch.float64)\n",
      "time for one step: 50.1929771900177\n",
      "tensor(5.2834, dtype=torch.float64)\n",
      "time for one step: 49.81332492828369\n",
      "tensor(5.3434, dtype=torch.float64)\n",
      "time for one step: 57.99526333808899\n",
      "tensor(4.8123, dtype=torch.float64)\n",
      "time for one step: 56.91121792793274\n",
      "tensor(5.2744, dtype=torch.float64)\n",
      "time for one step: 58.51637244224548\n",
      "tensor(4.8949, dtype=torch.float64)\n",
      "time for one step: 55.210490226745605\n",
      "tensor(5.0747, dtype=torch.float64)\n",
      "time for one step: 55.684274673461914\n",
      "tensor(5.0368, dtype=torch.float64)\n",
      "time for one step: 52.841604232788086\n",
      "tensor(4.9721, dtype=torch.float64)\n",
      "time for one step: 54.44855189323425\n",
      "tensor(5.1997, dtype=torch.float64)\n",
      "time for one step: 54.48831868171692\n",
      "tensor(5.1560, dtype=torch.float64)\n",
      "time for one step: 56.667710065841675\n",
      "tensor(4.6699, dtype=torch.float64)\n",
      "time for one step: 53.11137795448303\n",
      "tensor(4.6878, dtype=torch.float64)\n",
      "time for one step: 51.8695342540741\n",
      "tensor(4.9800, dtype=torch.float64)\n",
      "time for one step: 47.941378355026245\n",
      "tensor(5.2006, dtype=torch.float64)\n",
      "time for one step: 48.63495373725891\n",
      "tensor(4.7928, dtype=torch.float64)\n",
      "time for one step: 49.406996726989746\n",
      "tensor(5.1770, dtype=torch.float64)\n",
      "time for one step: 47.94735765457153\n",
      "tensor(5.0057, dtype=torch.float64)\n",
      "time for one step: 49.22236943244934\n",
      "tensor(5.0279, dtype=torch.float64)\n",
      "time for one step: 46.49325346946716\n",
      "tensor(5.3682, dtype=torch.float64)\n",
      "time for one step: 42.88311553001404\n",
      "tensor(4.5523, dtype=torch.float64)\n",
      "time for one step: 43.989747285842896\n",
      "tensor(4.8691, dtype=torch.float64)\n",
      "time for one step: 41.77697730064392\n",
      "tensor(5.0970, dtype=torch.float64)\n",
      "time for one step: 42.495339155197144\n",
      "tensor(4.8056, dtype=torch.float64)\n",
      "time for one step: 41.81863212585449\n",
      "tensor(4.7979, dtype=torch.float64)\n",
      "time for one step: 37.839200258255005\n",
      "tensor(4.9480, dtype=torch.float64)\n",
      "time for one step: 35.40472865104675\n",
      "tensor(4.8732, dtype=torch.float64)\n",
      "time for one step: 35.819331884384155\n",
      "tensor(4.9851, dtype=torch.float64)\n",
      "time for one step: 32.49704194068909\n",
      "tensor(5.2522, dtype=torch.float64)\n",
      "time for one step: 33.148818016052246\n",
      "tensor(4.8891, dtype=torch.float64)\n",
      "time for one step: 31.304409503936768\n",
      "tensor(4.8486, dtype=torch.float64)\n",
      "time for one step: 30.76192355155945\n",
      "tensor(4.8925, dtype=torch.float64)\n",
      "time for one step: 29.983394861221313\n",
      "tensor(5.0900, dtype=torch.float64)\n",
      "time for one step: 27.667919874191284\n",
      "tensor(4.9760, dtype=torch.float64)\n",
      "time for one step: 26.785515546798706\n",
      "tensor(4.8258, dtype=torch.float64)\n",
      "time for one step: 27.201468229293823\n",
      "tensor(5.1051, dtype=torch.float64)\n",
      "time for one step: 25.15586256980896\n",
      "tensor(5.2088, dtype=torch.float64)\n",
      "time for one step: 25.185858488082886\n",
      "tensor(4.9496, dtype=torch.float64)\n",
      "time for one step: 25.512954473495483\n",
      "tensor(5.2178, dtype=torch.float64)\n",
      "time for one step: 26.360616445541382\n",
      "tensor(5.0453, dtype=torch.float64)\n",
      "time for one step: 24.980902671813965\n",
      "tensor(5.0899, dtype=torch.float64)\n",
      "time for one step: 26.36140775680542\n",
      "tensor(5.1013, dtype=torch.float64)\n",
      "time for one step: 23.90907859802246\n",
      "tensor(4.7611, dtype=torch.float64)\n",
      "time for one step: 23.59860396385193\n",
      "tensor(4.9658, dtype=torch.float64)\n",
      "time for one step: 24.43499755859375\n",
      "tensor(4.8238, dtype=torch.float64)\n",
      "time for one step: 23.808942556381226\n",
      "tensor(5.1407, dtype=torch.float64)\n",
      "time for one step: 24.63277268409729\n",
      "tensor(5.0983, dtype=torch.float64)\n",
      "time for one step: 24.024475574493408\n",
      "tensor(4.9167, dtype=torch.float64)\n",
      "time for one step: 23.75970220565796\n",
      "tensor(4.9071, dtype=torch.float64)\n",
      "time for one step: 24.744023323059082\n",
      "tensor(4.4979, dtype=torch.float64)\n",
      "time for one step: 23.113410234451294\n",
      "tensor(4.3755, dtype=torch.float64)\n",
      "time for one step: 23.175771474838257\n",
      "tensor(4.7191, dtype=torch.float64)\n",
      "time for one step: 24.43023371696472\n",
      "tensor(4.7195, dtype=torch.float64)\n",
      "time for one step: 25.50215983390808\n",
      "tensor(4.6367, dtype=torch.float64)\n",
      "time for one step: 25.215949058532715\n",
      "tensor(4.8168, dtype=torch.float64)\n",
      "time for one step: 25.135881185531616\n",
      "tensor(4.8913, dtype=torch.float64)\n",
      "time for one step: 24.922963619232178\n",
      "tensor(5.1559, dtype=torch.float64)\n",
      "time for one step: 25.792388200759888\n",
      "tensor(4.8422, dtype=torch.float64)\n",
      "time for one step: 26.01552414894104\n",
      "tensor(5.1048, dtype=torch.float64)\n",
      "time for one step: 26.26274800300598\n",
      "tensor(5.1394, dtype=torch.float64)\n",
      "time for one step: 27.128305912017822\n",
      "tensor(4.7996, dtype=torch.float64)\n",
      "time for one step: 28.454007148742676\n",
      "tensor(4.7464, dtype=torch.float64)\n",
      "time for one step: 26.497551918029785\n",
      "tensor(4.4820, dtype=torch.float64)\n",
      "time for one step: 27.611688375473022\n",
      "tensor(4.8957, dtype=torch.float64)\n",
      "time for one step: 29.570518016815186\n",
      "tensor(4.5774, dtype=torch.float64)\n",
      "time for one step: 27.88069796562195\n",
      "tensor(4.9492, dtype=torch.float64)\n",
      "time for one step: 29.30616855621338\n",
      "tensor(4.7809, dtype=torch.float64)\n",
      "time for one step: 31.149062395095825\n",
      "tensor(4.5561, dtype=torch.float64)\n",
      "time for one step: 29.775846004486084\n",
      "tensor(4.7625, dtype=torch.float64)\n",
      "time for one step: 30.307467937469482\n",
      "tensor(5.1179, dtype=torch.float64)\n",
      "time for one step: 30.756820917129517\n",
      "tensor(4.8674, dtype=torch.float64)\n",
      "time for one step: 32.46092629432678\n",
      "tensor(4.9398, dtype=torch.float64)\n",
      "time for one step: 32.56942796707153\n",
      "tensor(4.2905, dtype=torch.float64)\n",
      "time for one step: 33.40357041358948\n",
      "tensor(4.7341, dtype=torch.float64)\n",
      "time for one step: 33.007413387298584\n",
      "tensor(4.3233, dtype=torch.float64)\n",
      "time for one step: 33.565512895584106\n",
      "tensor(4.6414, dtype=torch.float64)\n",
      "time for one step: 34.10237693786621\n",
      "tensor(4.1641, dtype=torch.float64)\n",
      "time for one step: 33.1017119884491\n",
      "tensor(4.7218, dtype=torch.float64)\n",
      "time for one step: 33.477357625961304\n",
      "tensor(4.7328, dtype=torch.float64)\n",
      "time for one step: 37.243462800979614\n",
      "tensor(4.5934, dtype=torch.float64)\n",
      "time for one step: 33.13614273071289\n",
      "tensor(4.4390, dtype=torch.float64)\n",
      "time for one step: 32.603859186172485\n",
      "tensor(4.8940, dtype=torch.float64)\n",
      "time for one step: 36.16144323348999\n",
      "tensor(4.5771, dtype=torch.float64)\n",
      "time for one step: 32.91892075538635\n",
      "tensor(4.6197, dtype=torch.float64)\n",
      "time for one step: 32.67392444610596\n",
      "tensor(4.5272, dtype=torch.float64)\n",
      "time for one step: 33.8215229511261\n",
      "tensor(4.5377, dtype=torch.float64)\n",
      "time for one step: 36.13357162475586\n",
      "tensor(4.8880, dtype=torch.float64)\n",
      "time for one step: 37.25967216491699\n",
      "tensor(4.7329, dtype=torch.float64)\n",
      "time for one step: 35.370750188827515\n",
      "tensor(4.4293, dtype=torch.float64)\n",
      "time for one step: 35.008097887039185\n",
      "tensor(4.7268, dtype=torch.float64)\n",
      "time for one step: 36.19450402259827\n",
      "tensor(4.9626, dtype=torch.float64)\n",
      "time for one step: 36.13862490653992\n",
      "tensor(4.2816, dtype=torch.float64)\n",
      "time for one step: 34.84231090545654\n",
      "tensor(4.3740, dtype=torch.float64)\n",
      "time for one step: 37.1715030670166\n",
      "tensor(4.1643, dtype=torch.float64)\n",
      "time for one step: 36.70279574394226\n",
      "tensor(4.6693, dtype=torch.float64)\n",
      "time for one step: 36.957295179367065\n",
      "tensor(4.6043, dtype=torch.float64)\n",
      "time for one step: 39.55952429771423\n",
      "tensor(4.1357, dtype=torch.float64)\n",
      "time for one step: 37.94439935684204\n",
      "tensor(4.0437, dtype=torch.float64)\n",
      "time for one step: 38.46970200538635\n",
      "tensor(4.6366, dtype=torch.float64)\n",
      "time for one step: 38.98222732543945\n",
      "tensor(4.3972, dtype=torch.float64)\n",
      "time for one step: 40.16613459587097\n",
      "tensor(4.1587, dtype=torch.float64)\n",
      "time for one step: 41.137171030044556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4873, dtype=torch.float64)\n",
      "time for one step: 41.384572982788086\n",
      "tensor(4.4857, dtype=torch.float64)\n",
      "time for one step: 41.64253330230713\n",
      "tensor(4.6225, dtype=torch.float64)\n",
      "time for one step: 41.52451801300049\n",
      "tensor(4.3569, dtype=torch.float64)\n",
      "time for one step: 43.72737431526184\n",
      "tensor(4.3862, dtype=torch.float64)\n",
      "time for one step: 42.949196577072144\n",
      "tensor(4.5029, dtype=torch.float64)\n",
      "time for one step: 43.387335777282715\n",
      "tensor(4.6602, dtype=torch.float64)\n",
      "time for one step: 43.791762590408325\n",
      "tensor(4.5523, dtype=torch.float64)\n",
      "time for one step: 44.31623959541321\n",
      "tensor(4.4601, dtype=torch.float64)\n",
      "time for one step: 45.21805191040039\n",
      "tensor(4.4686, dtype=torch.float64)\n",
      "time for one step: 44.495729207992554\n",
      "tensor(4.3926, dtype=torch.float64)\n",
      "time for one step: 45.496755599975586\n",
      "tensor(4.4780, dtype=torch.float64)\n",
      "time for one step: 47.26475691795349\n",
      "tensor(4.4807, dtype=torch.float64)\n",
      "time for one step: 45.69879484176636\n",
      "tensor(4.5379, dtype=torch.float64)\n",
      "time for one step: 45.64818978309631\n",
      "tensor(4.5362, dtype=torch.float64)\n",
      "time for one step: 45.65105748176575\n",
      "tensor(4.1703, dtype=torch.float64)\n",
      "time for one step: 49.330575704574585\n",
      "tensor(4.5748, dtype=torch.float64)\n",
      "time for one step: 47.42848491668701\n",
      "tensor(4.6573, dtype=torch.float64)\n",
      "time for one step: 47.31901788711548\n",
      "tensor(4.1537, dtype=torch.float64)\n",
      "time for one step: 47.23040509223938\n",
      "tensor(4.2749, dtype=torch.float64)\n",
      "time for one step: 47.8117253780365\n",
      "tensor(4.7364, dtype=torch.float64)\n",
      "time for one step: 49.778374671936035\n",
      "tensor(4.1977, dtype=torch.float64)\n",
      "time for one step: 47.70653796195984\n",
      "tensor(4.2378, dtype=torch.float64)\n",
      "time for one step: 47.712594747543335\n",
      "tensor(4.8019, dtype=torch.float64)\n",
      "time for one step: 47.62376809120178\n",
      "tensor(4.7297, dtype=torch.float64)\n",
      "time for one step: 48.46761083602905\n",
      "tensor(4.3223, dtype=torch.float64)\n",
      "time for one step: 46.72354435920715\n",
      "tensor(4.6950, dtype=torch.float64)\n",
      "time for one step: 47.64945983886719\n",
      "tensor(4.2903, dtype=torch.float64)\n",
      "time for one step: 48.91363453865051\n",
      "tensor(4.2737, dtype=torch.float64)\n",
      "time for one step: 47.763848543167114\n",
      "tensor(4.2735, dtype=torch.float64)\n",
      "time for one step: 48.27423119544983\n",
      "tensor(4.3422, dtype=torch.float64)\n",
      "time for one step: 47.987292766571045\n",
      "tensor(4.1889, dtype=torch.float64)\n",
      "time for one step: 48.893638134002686\n",
      "tensor(4.4339, dtype=torch.float64)\n",
      "time for one step: 47.228249311447144\n",
      "tensor(4.4692, dtype=torch.float64)\n",
      "time for one step: 47.00800323486328\n",
      "tensor(4.3437, dtype=torch.float64)\n",
      "time for one step: 49.52176880836487\n",
      "tensor(4.0253, dtype=torch.float64)\n",
      "time for one step: 47.31128644943237\n",
      "tensor(4.1420, dtype=torch.float64)\n",
      "time for one step: 49.21281671524048\n",
      "tensor(4.0626, dtype=torch.float64)\n",
      "time for one step: 48.96315240859985\n",
      "tensor(4.4320, dtype=torch.float64)\n",
      "time for one step: 50.44943308830261\n",
      "tensor(4.6088, dtype=torch.float64)\n",
      "time for one step: 49.695725440979004\n",
      "tensor(4.4442, dtype=torch.float64)\n",
      "time for one step: 49.18828105926514\n",
      "tensor(4.0454, dtype=torch.float64)\n",
      "time for one step: 48.725308656692505\n",
      "tensor(4.5407, dtype=torch.float64)\n",
      "time for one step: 47.805108308792114\n",
      "tensor(4.2221, dtype=torch.float64)\n",
      "time for one step: 50.829241037368774\n",
      "tensor(3.9530, dtype=torch.float64)\n",
      "time for one step: 50.839412689208984\n",
      "tensor(4.1835, dtype=torch.float64)\n",
      "time for one step: 51.520291328430176\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-7598ddc96f55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mS_lst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS_lst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full Backprop Package\\deep_nmf.ipynb\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full Backprop Package\\lsqnonneg_module.ipynb\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full Backprop Package\\lsqnonneg_module.ipynb\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, input, A)\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Deep NMF\\Code\\Cathy Code\\Full Backprop Package\\lsqnonneg_module.ipynb\u001b[0m in \u001b[0;36mlsqnonneg_tensor_version\u001b[1;34m(C, D)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\nnls.py\u001b[0m in \u001b[0;36mnnls\u001b[1;34m(A, b, maxiter)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_nnls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"too many iterations\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training process!\n",
    "\n",
    "# setting training parameters\n",
    "epoch = 5\n",
    "lr = 10000\n",
    "loss_lst = []\n",
    "# train!\n",
    "for epo in range(epoch):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = 50, shuffle = True)\n",
    "    total_loss = 0\n",
    "    for (i, (inputs, label)) in enumerate(dataloader):\n",
    "        t1 = time.time()\n",
    "        inputs = inputs.view([inputs.shape[0], inputs.shape[2]])\n",
    "        inputs, label = Variable(inputs), Variable(label)\n",
    "        S_lst = net(inputs)\n",
    "        loss = loss_func(net, inputs, S_lst)\n",
    "        loss.backward()\n",
    "        print(loss.data)\n",
    "        loss_lst.append(loss.data)\n",
    "        t2 = time.time()\n",
    "        print('time for one step:', t2 -t1)\n",
    "        total_loss += loss.data\n",
    "        for A in net.parameters():\n",
    "            A.data = A.data.sub_(lr*A.grad.data)\n",
    "            A.data = A.data.clamp(min = 0)\n",
    "    print('epoch = ', epo, '\\n', total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_whole_output(net, dataset, param_lst = None):\n",
    "    history = Writer()\n",
    "    # initialize the network with certain initial value\n",
    "    if param_lst is not None:\n",
    "        for (i,param) in enumerate(net.parameters()):\n",
    "            param.data = param_lst[i]\n",
    "    # start to forward propagate, 100 at a time\n",
    "    n = len(dataset)\n",
    "    if n%100 == 0:\n",
    "        batch_num = n/100\n",
    "    else:\n",
    "        batch_num = n//100 + 1\n",
    "    print('batch_num = ', batch_num, '\\n')\n",
    "    for i in range(batch_num):\n",
    "        print('current at batch:', i)\n",
    "        try:\n",
    "            (inputs, label) = dataset[i*100:(i+1)*100]\n",
    "        except:\n",
    "            (inputs, label) = dataset[i*100:]\n",
    "        history.add_tensor('label', label)\n",
    "        output = net(inputs)\n",
    "        history.add_tensor('output', output)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the S matrix as the features for the data and the do linear regression to see how it works out\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total S matrix and the total label\n",
    "S_lst = history.get('output')\n",
    "S_lst = [S_lst[i][0].data for i in range(len(S_lst))]\n",
    "S = torch.cat(S_lst, dim = 0)\n",
    "label = history.cat_lst('label')\n",
    "S = S.numpy()\n",
    "S_normalized = (S - np.reshape(np.mean(S,1), [-1,1]))/np.reshape(np.std(S,1),[-1,1])\n",
    "label = label.numpy()\n",
    "# encode the label\n",
    "le = LabelEncoder()\n",
    "le.fit(label)\n",
    "label = le.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24482648837949697"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use logistic regression to classify\n",
    "clf = LogisticRegression()\n",
    "clf.fit(S_normalized, label)\n",
    "pred = clf.predict(S_normalized)\n",
    "np.sum(pred == label)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  10\n",
      "acc =  0.24992040751353073\n",
      "C =  100\n",
      "acc =  0.2502387774594078\n"
     ]
    }
   ],
   "source": [
    "for C in [10, 100, 1000]:\n",
    "    clf = SVC(kernel = 'linear', C = C)\n",
    "    clf.fit(S_normalized, label)\n",
    "    pred = clf.predict(S_normalized)\n",
    "    print('C = ', C)\n",
    "    print('acc = ', np.sum(pred == label)/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling nnmf(X,20) in matlab, get the S and then classify\n",
    "directory = 'C:/Users/rzhang\\Dropbox\\Deep NMF\\Code\\Eli code\\full backprop in matlab/20_news_group'\n",
    "matlab_data = sio.loadmat(directory)\n",
    "S_matlab = matlab_data.get('S')\n",
    "S_matlab = S_matlab.T\n",
    "label_matlab = matlab_data.get('classes')\n",
    "label_matlab = label_matlab.T\n",
    "\n",
    "#normalize S_matlab\n",
    "S_matlab_normalized = (S_matlab - np.reshape(np.mean(S_matlab,1), [-1,1]))/np.reshape(np.std(S_matlab,1),[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23718560967844635"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(S_matlab_normalized, label_matlab.ravel())\n",
    "pred = clf.predict(S_matlab_normalized)\n",
    "np.sum(pred == label_matlab.ravel())/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  1\n",
      "acc =  0.24434893346068132\n",
      "C =  10\n",
      "acc =  0.24456118009126604\n",
      "C =  100\n",
      "acc =  0.24456118009126604\n"
     ]
    }
   ],
   "source": [
    "for C in [1, 10, 100]:\n",
    "    clf = SVC(kernel = 'linear', C = C)\n",
    "    clf.fit(S_matlab_normalized, label_matlab.ravel())\n",
    "    pred = clf.predict(S_matlab_normalized)\n",
    "    print('C = ', C)\n",
    "    print('acc = ', np.sum(pred == label_matlab.ravel())/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_lst = np.load('20_news_group_loss_lst.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_lst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
